\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[swedish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{enumerate}

%------------------------------------------
% Math
%------------------------------------------
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

%------------------------------------------
% For source code
%------------------------------------------
\usepackage{color}
\usepackage{xcolor}
\usepackage{listings}

\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

%------------------------------------------

\title{Sammanfattning EDA040}
\author{Felix Mulder}
\begin{document}
\maketitle
\newpage


\section{Deadlock Analysis}
Resource allocation graphs are used to determine if a program can deadlock.
For a program to end up in a deadlock there are a few requirements.
\begin{itemize}
  \item Mutual exclusion: at least one resource is held in a non-shareable mode.
  \item Hold and wait: there must exist a process that is holding at least one
        resource and simultaneously waiting for resources that are held by other
        processes.
  \item No preemption: resources cannot be preempted; the resource can only be 
        released voluntarily by the resource holding it.
  \item Circular wait: There must exist a set of processes waiting for each other
        in a circular structure. I.e: p1 waits for p2, p2 waits for p3, p3 waits
        for p1.
\end{itemize}

To draw a resource allocation graph from source code:
\begin{enumerate}
  \item Draw boxes for each resource.
  \item For each thread (i) and line (j), draw a bubble with $T_{ij}$. If a thread
        takes, then draw a line to the resource. For $T_{i(j+1)}$ draw a line from the
        resource to the thread.
  \item If $T_{ij}$ only emits or only absorbs arrows, you don't have to keep
        it in the graph.
  \item For resources that exist as multiple instances, draw dots inside the resource.
        If a cycle exists containing a multiple instance resource, then it may be a
        false cycle.
\end{enumerate}

Cycles in the graph indicate the possibility of deadlocks.
\begin{center}
  \includegraphics[scale=0.2]{res_alloc}
\end{center}

\section{Process synchronization}

The critical section problem could be solved simply by disallowing interrupts
on a single core cpu. With multiple cores, however, disabling these interrupts
will be too time consuming.

\subsection{Dekker's Algorithm}
Dekker's algorithm solves the process synchronization problem with busy waits.
Meaning: using the below specified code results in a correctl handling of
critical areas. Alas, the threads spend CPU cycles in the while loop, needlessly.
If we implement Dekker's we should compliment it with wait/notify functionality.
Without this improvement the semaphores can be referred to as spinlocks.
The only advantage with using spinlocks is that there is no context switch
required.

\begin{lstlisting}[label=dekkers,caption=Dekker's Algorithm]
public class Dekkers extends MutualExclusion {
  public Dekkers () {
    flag[0] = false;
    flag[1] = false;
    turn = TURN_0;
  }

  public void enteringCriticalSection (int t) {
    int other;

    other = 1 - t;

    flag[t] = true;
    turn = other;

    while ((flag[other] == true) && (turn == other)) {
      Thread.yield();
    }
  }

  public void leavingCriticalSection (int t) {
    flag[t] = false;
  }

  private volatile int turn;
  private volatile boolean[] flag = new boolean[2];
}
\end{lstlisting}

\subsection{Race condition}
A race condition is when multiple threads access and manipulate the same
data concurrently, and where outcome of the execution depends on the
particular order in which access takes place.

\subsection{Mutual Exclustion}
If thread $T_i$ is executing in its critical section, then no other threads
can be executing in their critical sections.

\subsection{Progress}
If no thread is executing in its critical section and there exist threads
that wish to enter their critical sections, then only the threads not executing
in their critical section get to partake in the process of deciding which
thread gets to execute its critical section next.

\subsection{Starvation}
When some threads are allowed to execute and make progress, but others are
left ``starving.''

\subsection{Livelock}
No thread makes progress, but they keep executing.

\subsection{Bounded waiting}
There exists a limit to the amount of times a thread will wait for other
threads before its request to enter a critical area is granted. (This
prevents starvation in a single thread.)

\subsection{Drifting}
The following piece of code will cause accumulative drift.
\begin{lstlisting}[label=drift,caption=Drift example]
while (!isInterrupted()) {
              sleep(100); foo.bar();
}
\end{lstlisting}

Sleep specifies a minimun time to sleep, and a context switch may have ocurred
after sleep and before the method call thus drift is accumulated.

\begin{lstlisting}[label=drift-fix,caption=Drift fixed]
long t = System.currentTimeMillis();
while (!isInterrupted()) {
  foo.bar();
  t += 100;
  long diff = t - System.currentTimeMillis();
  if (diff > 0) sleep(diff);
}
\end{lstlisting}

Even with this fix, sleep still causes a minimum busy wait.

\subsection{volatile, transient keywords}
Volatile means that the compiler is not allowed to cache the value of this
variable. It should be updated before evaluation.

Transient means that the variable has no meaning outside of its current context
if the variable is passed along with a serialized object over a network, it
gets set to ``null'' or its equivalence.

\section{Scheduling}
\subsection{Priority inversion phenomenon}
Occurs when a low priority thread manages to lock a resource and this thread
is then interrupted by a higher priority thread. When the thread requests the
same resource, the lower thread blocks the higher thread and can thus resume
its execution. (Despite being lower prioritized than the other thread.)
If we called the highest prioritized thead A, and call the lowest Z. If Z
blocks A, and Z is interrupted by a higher prioritized thread (M?) that doesn't
share its resources, then this thread (M) also blocks A. This is called a 
\emph{prioriy inversion} since Z and M will execute before A.

\subsection{Priority inheritence protocol}
The basic idea is to modify the priority of the tasks causing the blocking. In
particular when Z blocks higher prioritized tasks, it temporarily inherits the
highest priority of the blocked tasks. This prevents medium prioritized threads
from preempting Z and prolonging the blocking duration.
\subsubsection{Basic}
Raises the priority of the low priority thread temporarily
\subsubsection{Priority Ceiling Protocol}
To bound the priority inversion phenomenon and preent the formation of deadlocks
and chained blocking; PCP extends the priority inheritence protocol with a
rule for granting a lock request.

When a job enters a critical section it receives the \emph{priority ceiling} 
equal to the highest prioritized job able to access said resource, meaning that
once it enters the critical region. This means that the only time it is
interrupted is when a job with higher priority needs to run. (The interrupting
job doesn't access the lower prioritized job's resource.)

If a job with higher priority than the currently running job in the semaphore
tries to gain access, its priority is transferred to the lower prioritized job
ensuring that a job won't be interrupted again by some job of said priority or
lower.

\begin{enumerate}
  \item Each semaphore is assigned a priority ceiling equal to the highest
        priority of jobs that can lock it.
  \item The job with the highest priority gets to run first.
  \item The job running locks a semaphore.
  \item Another job tries to interrupt the currently running job, but if said
        job has a lower priority than the priority ceiling, the first job
        continues to run. If the interrupting job had a higher priority than
        the job running inside the semaphore, its priority is transferred to the
        currently running job. (Priority inheritence)
  \item When no others jobs are blocked by the thread it resumes its original
        priority, i.e. its ``nominal priority.''
  \item Priority inheritence is transitive. I.e. if job $J_3$ blocks $J_2$ which
        in turn blocks $J_1$ then $J_3$ may inherit the priority from $J_1$.
\end{enumerate}

http://fileadmin.cs.lth.se/cs/Education/EDA040/lecture/rtpL5.pdf
\subsubsection{Immediate inheritence}
The priority of the thread running in a semaphore is immediately raised to the
ceiling priority.

\subsection{Direct blocking}
Occurs when a higher-priority job tries to acquire resources held by a job
with lower priority.

\subsection{Push-through blocking}
Occurs when a medium priority job is blocked by a lower priority job that has
inherited a higher priority from a job it directly blocks. This is necessary
to avoid unbounded priority inversion.

\subsection{Rate monotonic scheduling}
Scheduling by rate of occurrence. I.e. a job that has a high occurrence rate is
highly prioritized. A set of tasks is said to be schedulable by the rate monotonic 
algorithm if 
\begin{center}
  $\sum_{i=1}^{n} \frac{C_i}{T_i} \leq n(2^{1/n}-1)$
\end{center}

The tasks are also schedulable if $R_i \leq C_i$ for all jobs. We define $R_i$ as:

\begin{center}
  $R_i = C_i + B_i + \sum_{j=1}^{i-1} \ceil{\frac{R_i}{T_j}}C_j$
\end{center}

\subsection{Chained blocking}
When a highly prioritized job needs to collect resources held by two or more
lower prioritized jobs, meaning it has to wait for a series of lower prioritized
jobs to finish before managing to complete its own tasks.

\end{document}
